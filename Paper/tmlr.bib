@inproceedings{songCVPR16LiftedStructured,
    Author = {Hyun Oh Song and Yu Xiang and Stefanie Jegelka and Silvio Savarese},
    Title = {Deep Metric Learning via Lifted Structured Feature Embedding},
    Booktitle = {Computer Vision and Pattern Recognition (CVPR)},
    Year = {2016}
}


@inproceedings{NIPS2016N-PairLoss,
 author = {Sohn, Kihyuk},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Improved Deep Metric Learning with Multi-class N-pair Loss Objective},
 url = {https://proceedings.neurips.cc/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf},
 volume = {29},
 year = {2016}
}




@InProceedings{ICML22GeometricMultimodal,
  title = 	 {Geometric Multimodal Contrastive Representation Learning},
  author =       {Poklukar, Petra and Vasco, Miguel and Yin, Hang and Melo, Francisco S. and Paiva, Ana and Kragic, Danica},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {17782--17800},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/poklukar22a/poklukar22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/poklukar22a.html}
}



@inproceedings{bui2021self,
  title={Self-Supervised Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving Transformations},
  author={Bui, Nghi DQ and Yu, Yijun and Jiang, Lingxiao},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={511--521},
  year={2021}
}

@inproceedings{qin2021world,
  title={The world is binary: Contrastive learning for denoising next basket recommendation},
  author={Qin, Yuqi and Wang, Pengfei and Li, Chenliang},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={859--868},
  year={2021}
}

@inproceedings{vo2019composing,
  title={Composing text and image for image retrieval-an empirical odyssey},
  author={Vo, Nam and Jiang, Lu and Sun, Chen and Murphy, Kevin and Li, Li-Jia and Fei-Fei, Li and Hays, James},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6439--6448},
  year={2019}
}

@inproceedings{wen2021comprehensive,
  title={Comprehensive linguistic-visual composition network for image retrieval},
  author={Wen, Haokun and Song, Xuemeng and Yang, Xin and Zhan, Yibing and Nie, Liqiang},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1369--1378},
  year={2021}
}

@inproceedings{gao2020fashionbert,
  title={Fashionbert: Text and image matching with adaptive loss for cross-modal retrieval},
  author={Gao, Dehong and Jin, Linbo and Chen, Ben and Qiu, Minghui and Li, Peng and Wei, Yi and Hu, Yi and Wang, Hao},
  booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2251--2260},
  year={2020}
}

@inproceedings{hong2021gilbert,
  title={GilBERT: Generative Vision-Language Pre-Training for Image-Text Retrieval},
  author={Hong, Weixiang and Ji, Kaixiang and Liu, Jiajia and Wang, Jian and Chen, Jingdong and Chu, Wei},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1379--1388},
  year={2021}
}

@inproceedings{ma2020large,
  title={Large-scale image retrieval with sparse binary projections},
  author={Ma, Changyi and Gu, Chonglin and Li, Wenye and Cui, Shuguang},
  booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1817--1820},
  year={2020}
}

@inproceedings{novak2015large,
  title={Large-scale image retrieval using neural net descriptors},
  author={Novak, David and Batko, Michal and Zezula, Pavel},
  booktitle={Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval},
  pages={1039--1040},
  year={2015}
}

@inproceedings{huang2017deep,
  title={Deep multimodal embedding model for fine-grained sketch-based image retrieval},
  author={Huang, Fei and Cheng, Yong and Jin, Cheng and Zhang, Yuejie and Zhang, Tao},
  booktitle={Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={929--932},
  year={2017}
}



@inproceedings{hu2016natural,
  title={Natural language object retrieval},
  author={Hu, Ronghang and Xu, Huazhe and Rohrbach, Marcus and Feng, Jiashi and Saenko, Kate and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4555--4564},
  year={2016}
}

@inproceedings{chen2017beyond,
  title={Beyond triplet loss: a deep quadruplet network for person re-identification},
  author={Chen, Weihua and Chen, Xiaotang and Zhang, Jianguo and Huang, Kaiqi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={403--412},
  year={2017}
}


@article{chen2020simple,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2002.05709},
  year={2020}
}



@inproceedings{NEURIPS2020_supervised_contrastive,
 author = {Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {18661--18673},
 publisher = {Curran Associates, Inc.},
 title = {Supervised Contrastive Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{KebeAAAI2022,
  author = {Gaoussou Youssouf Kebe and Luke E. Richards and Edward Raff and Francis Ferraro and Cynthia Matuszek},
  title = {Bridging the Gap: Using Deep Acoustic Representations to Learn Grounded Language from Percepts and Raw Speech},
  year = {2022},
  publisher = {AAAI Press},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence}
}



@inproceedings{GoLD_UMBC,
title={A Spoken Language Dataset of Descriptions for Speech-Based Grounded Language Learning},
author={Gaoussou Youssouf Kebe and Padraig Higgins and Patrick Jenkins and Kasra Darvish and Rishabh Sachdeva and Ryan Barron and John Winder and Donald Engel and Edward Raff and Francis Ferraro and Cynthia Matuszek},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
year={2021},
url={https://openreview.net/forum?id=Yx9jT3fkBaD}
}

@InProceedings{triplet_loss_2021_CVPR,
    author    = {Nguyen, Andre T. and Richards, Luke E. and Kebe, Gaoussou Youssouf and Raff, Edward and Darvish, Kasra and Ferraro, Frank and Matuszek, Cynthia},
    title     = {Practical Cross-Modal Manifold Alignment for Robotic Grounded Language Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
    month     = {June},
    year      = {2021},
    pages     = {1613-1622}
}


@inproceedings{RichardsDarvishMatuszekCategoryFree20,
  title = {Learning {{Object Attributes}} with {{Category}}-{{Free Grounded Language}} from {{Deep Featurization}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Richards, Luke E. and Darvish, Kasra and Matuszek, Cynthia},
  year = {2020},
  month = oct,
  pages = {8400--8407},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9340824},
  keywords = {Feature extraction,Kasra,Learning systems,Natural languages,Object recognition,Robot sensing systems,Semantics,Visualization}
}




@INPROCEEDINGS{Nguyen-RSS-20,
    AUTHOR    = {Thao Nguyen AND Nakul Gopalan AND Roma Patel AND Matthew Corsaro AND Ellie Pavlick AND Stefanie Tellex},
    TITLE     = {{Robot Object Retrieval with Contextual Natural Language Queries}},
    BOOKTITLE = {Proceedings of Robotics: Science and Systems},
    YEAR      = {2020},
    ADDRESS   = {Corvalis, Oregon, USA},
    MONTH     = {July},
    DOI       = {10.15607/RSS.2020.XVI.080}
}



@INPROCEEDINGS{imagenet2009,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}
  }



@inproceedings{NIPS2012_alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{Pillai_Matuszek_2018,
  author = {Pillai, Nisha and Matuszek, Cynthia},
  title = {Unsupervised Selection of Negative Examples for Grounded Language Learning},
  year = {2022},
  publisher = {AAAI Press},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence}
}


@inproceedings{batchnorm2015,
  author    = {Sergey Ioffe and
               Christian Szegedy},
  editor    = {Francis R. Bach and
               David M. Blei},
  title     = {Batch Normalization: Accelerating Deep Network Training by Reducing
               Internal Covariate Shift},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning,
               {ICML} 2015, Lille, France, 6-11 July 2015},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {37},
  pages     = {448--456},
  publisher = {JMLR.org},
  year      = {2015},
  url       = {http://proceedings.mlr.press/v37/ioffe15.html},
}





@inproceedings{kingma_adam_2015,
  author={Diederik P. Kingma and Jimmy Ba},
  title={Adam: A Method for Stochastic Optimization},
  year={2015},
  cdate={1420070400000},
  url={http://arxiv.org/abs/1412.6980},
  booktitle={ICLR},
}



@inproceedings{NEURIPS2020_nvae,
 author = {Vahdat, Arash and Kautz, Jan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {19667--19679},
 publisher = {Curran Associates, Inc.},
 title = {NVAE: A Deep Hierarchical Variational Autoencoder},
 url = {https://proceedings.neurips.cc/paper/2020/file/e3b21256183cf7c2c7a66be163579d37-Paper.pdf},
 volume = {33},
 year = {2020}
}



@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}


@article{jordan1999introduction,
  title={An introduction to variational methods for graphical models},
  author={Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  journal={Machine learning},
  volume={37},
  number={2},
  pages={183--233},
  year={1999},
  publisher={Springer}
}


@article{mcrae2005semantic,
  title={Semantic feature production norms for a large set of living and nonliving things},
  author={McRae, Ken and Cree, George S and Seidenberg, Mark S and McNorgan, Chris},
  journal={Behavior research methods},
  volume={37},
  number={4},
  pages={547--559},
  year={2005},
  publisher={Springer}
}





@inproceedings{Mooney2008Grounded,
author = {Mooney, Raymond J.},
title = {Learning to Connect Language and Perception},
year = {2008},
isbn = {9781577353683},
publisher = {AAAI Press},
booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3},
pages = {1598–1601},
numpages = {4},
location = {Chicago, Illinois},
series = {AAAI'08}
}



@inproceedings{tseng-NLU-NLG-2020-generative,
    title = "A Generative Model for Joint Natural Language Understanding and Generation",
    author = "Tseng, Bo-Hsiang  and
      Cheng, Jianpeng  and
      Fang, Yimai  and
      Vandyke, David",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.163",
    doi = "10.18653/v1/2020.acl-main.163",
    pages = "1795--1807",
}



@incollection{NIPS2017_7246,
title = {Neural Expectation Maximization},
author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {6691--6701},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7246-neural-expectation-maximization.pdf}
}


@InProceedings{pmlr-v48-xieb16,
  title = 	 {Unsupervised Deep Embedding for Clustering Analysis},
  author = 	 {Junyuan Xie and Ross Girshick and Ali Farhadi},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {478--487},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/xieb16.pdf},
  url = 	 {http://proceedings.mlr.press/v48/xieb16.html},
  abstract = 	 {Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.}
}


@inproceedings{castrejon2016learning,
  title={Learning Aligned Cross-Modal Representations from Weakly Aligned Data},
  author={Castrejon, Lluis and Aytar, Yusuf and Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on},
  year={2016},
  organization={IEEE}
}


@inproceedings{ayatar2016crossmodal,
  title={Cross-Modal Scene Networks}, 
  author={Aytar, Yusuf and Castrejon, Lluis and Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  year={2016},
}


@inproceedings{Pillai2019RoboNLP,
    author	= {Nisha Pillai and Cynthia Matuszek and Francis Ferraro},
    title	= {Deep Learning for Category-Free Grounded Language Acquisition},
    booktitle	= {Proc. of the NAACL Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics (NAACL-SpLU-RoboNLP)},
    year	= {2019},
    month       = {June},
    address     = {Minneapolis, MI, USA}
}

@inproceedings{yu-siskind-2013-grounded,
    title = "Grounded Language Learning from Video Described with Sentences",
    author = "Yu, Haonan  and
      Siskind, Jeffrey Mark",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P13-1006",
    pages = "53--63",
}


@InProceedings{VQA,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {{VQA}: {V}isual {Q}uestion {A}nswering},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2015},
}

@inproceedings{ALFRED20,
  title ={{ALFRED: A Benchmark for Interpreting Grounded
           Instructions for Everyday Tasks}},
  author={Mohit Shridhar and Jesse Thomason and
          Daniel Gordon and Yonatan Bisk and
          Winson Han and Roozbeh Mottaghi and
          Luke Zettlemoyer and Dieter Fox},
  booktitle = {The IEEE Conference on Computer Vision
              and Pattern Recognition (CVPR)},
  year = {2020},
  url  = {https://arxiv.org/abs/1912.01734}
}


@inproceedings{ren2012rgb,
  title={Rgb-(d) scene labeling: Features and algorithms},
  author={Ren, Xiaofeng and Bo, Liefeng and Fox, Dieter},
  booktitle={IEEE Computer Vision and Pattern Recognition},
  pages={2759--2766},
  year={2012},
  organization={IEEE}
}

@inproceedings{Lai_ICRA_2011,
    title = {{A large-scale hierarchical multi-view {\{}RGB-D{\}} object dataset}},
    year = {2011},
    booktitle = {2011 IEEE international conference on robotics and automation},
    author = {Lai, Kevin and Bo, Liefeng and Ren, Xiaofeng and Fox, Dieter},
    pages = {1817--1824},
    organization = {IEEE}
}



@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}




@inproceedings{akbik2019flair,
  title={FLAIR: An easy-to-use framework for state-of-the-art NLP},
  author={Akbik, Alan and Bergmann, Tanja and Blythe, Duncan and Rasul, Kashif and Schweter, Stefan and Vollgraf, Roland},
  booktitle={{NAACL} 2019, 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)},
  pages={54--59},
  year={2019}
}

@inproceedings{akbik-etal-2019-pooled,
    title = "Pooled Contextualized Embeddings for Named Entity Recognition",
    author = "Akbik, Alan  and
      Bergmann, Tanja  and
      Vollgraf, Roland",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1078",
    doi = "10.18653/v1/N19-1078",
    pages = "724--728",
}


@article{Schwartz2020GreenA,
  title={Green AI},
  author={Roy Schwartz and Jesse Dodge and N. A. Smith and Oren Etzioni},
  journal={Communications of the ACM},
  year={2020},
  volume={63},
  pages={54 - 63}
}



 @inproceedings{He_resnet_2016, 
 place={Las Vegas, NV, USA}, 
 title={Deep Residual Learning for Image Recognition}, ISBN={978-1-4673-8851-1}, url={http://ieeexplore.ieee.org/document/7780459/}, DOI={10.1109/CVPR.2016.90}, 
 booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
 publisher={IEEE}, 
 author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian}, 
 year={2016}, 
 month={Jun}, 
 pages={770–778}
 }




 @inproceedings{Maddison_ICLR_2017, 
 title={The concrete distribution: A continuous relaxation of discrete random variables}, 
 url={https://openreview.net/forum?id=S1jE5L5gl}, 
 booktitle={5th international conference on learning representations, ICLR 2017, toulon, france, april 24-26, 2017, conference track proceedings}, 
 publisher={OpenReview.net}, 
 author={Maddison, Chris J. and Mnih, Andriy and Teh, Yee Whye}, 
 year={2017}
 }



 @inproceedings{Hwang2021COMETATOMIC2O,
 title={COMET-ATOMIC 2020: On symbolic and neural commonsense knowledge graphs}, url={https://arxiv.org/pdf/2010.05953.pdf}, 
 note={Citation Key: Hwang2021COMETATOMIC2O}, booktitle={AAAI}, 
 author={Hwang, Jena D. and Bhagavatula, Chandra and Bras, Ronan Le and Da, Jeff and Sakaguchi, Keisuke and Bosselut, Antoine and Choi, Yejin}, 
 year={2021} 
 }



@inproceedings{Speer2017ConceptNet5A,
  title={ConceptNet 5.5: An Open Multilingual Graph of General Knowledge},
  author={R. Speer and Joshua Chin and Catherine Havasi},
  booktitle={AAAI},
  year={2017}
}


@inproceedings{DCNN2017Song,
author = {Song, Xinhang and Herranz, Luis and Jiang, Shuqiang},
title = {Depth CNNs for RGB-D Scene Recognition: Learning from Scratch Better than Transferring from RGB-CNNs},
year = {2017},
publisher = {AAAI Press},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {4271–4277},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI’17}
}


@inproceedings{nyga2018grounding, title={Grounding robot plans from natural language instructions with incomplete world knowledge}, author={Nyga, Daniel and Roy, Subhro and Paul, Rohan and Park, Daehyung and Pomarlan, Mihai and Beetz, Michael and Roy, Nicholas}, booktitle={Conference on Robot Learning}, pages={714--723}, year={2018} }

@inproceedings{macglashan15grounding,
title = {{Grounding English Commands to Reward Functions}},
author = {MacGlashan, James and Babes-Vroman, Monica and desJardins, Marie and Littman, Michael and Muresan, Smaranda and Squire, Shawn and Tellex, Stefanie and Arumugam, Dilip and Yang, Lei},
booktitle={{Robotics: Science and Systems}},
year = {2015}
}


@ARTICLE{Tell-Vinyals-2017,
  author={O. {Vinyals} and A. {Toshev} and S. {Bengio} and D. {Erhan}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge}, 
  year={2017},
  volume={39},
  number={4},
  pages={652-663},}
  
  
@INPROCEEDINGS{You-captioning-2016,  author={Q. {You} and H. {Jin} and Z. {Wang} and C. {Fang} and J. {Luo}},  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Image Captioning with Semantic Attention},   year={2016},  volume={},  number={},  pages={4651-4659},}
  

@inproceedings{Tells-story-Farhadi-2010,
author = {Farhadi, Ali and Hejrati, Mohsen and Sadeghi, Mohammad Amin and Young, Peter and Rashtchian, Cyrus and Hockenmaier, Julia and Forsyth, David},
title = {Every Picture Tells a Story: Generating Sentences from Images},
year = {2010},
isbn = {364215560X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the 11th European Conference on Computer Vision: Part IV},
pages = {15–29},
numpages = {15},
location = {Heraklion, Crete, Greece},
series = {ECCV’10}
}

@inproceedings{Carvalho-cooking-triplet,
author = {Carvalho, Micael and Cad\`{e}ne, R\'{e}mi and Picard, David and Soulier, Laure and Thome, Nicolas and Cord, Matthieu},
title = {Cross-Modal Retrieval in the Cooking Context: Learning Semantic Text-Image Embeddings},
year = {2018},
isbn = {9781450356572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209978.3210036},
doi = {10.1145/3209978.3210036},
booktitle = {The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {35–44},
numpages = {10},
keywords = {semantic embedding, cross-modal retrieval, deep learning},
location = {Ann Arbor, MI, USA},
series = {SIGIR ’18}
}



@inproceedings{salvador2017cooking,
  title={Learning Cross-modal Embeddings for Cooking Recipes and Food Images},
  author={Salvador, Amaia and Hynes, Nicholas and Aytar, Yusuf and Marin, Javier and 
          Ofli, Ferda and Weber, Ingmar and Torralba, Antonio},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}


@inproceedings{subramanya-bilmes-2008-soft,
    title = "Soft-Supervised Learning for Text Classification",
    author = "Subramanya, Amarnag  and
      Bilmes, Jeff",
    booktitle = "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2008",
    address = "Honolulu, Hawaii",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D08-1114",
    pages = "1090--1099",
}

@incollection{NIPS2013-EM-sampling,
title = {Learning Stochastic Feedforward Neural Networks},
author = {Tang, Charlie and Salakhutdinov, Russ R},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {530--538},
year = {2013},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5026-learning-stochastic-feedforward-neural-networks.pdf}
}


@InProceedings{Li_2019_ICCV,
author = {Li, Xia and Zhong, Zhisheng and Wu, Jianlong and Yang, Yibo and Lin, Zhouchen and Liu, Hong},
title = {Expectation-Maximization Attention Networks for Semantic Segmentation},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

@article{EM,
author = {Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
title = {Maximum Likelihood from Incomplete Data Via the EM Algorithm},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
volume = {39},
number = {1},
pages = {1-22},
keywords = {maximum likelihood, incomplete data, em algorithm, posterior mode},
doi = {10.1111/j.2517-6161.1977.tb01600.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1977.tb01600.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1977.tb01600.x},
abstract = {Summary A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
year = {1977}
}


@INPROCEEDINGS{Resnet_2016_He,
  author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},}
  
@inproceedings{li2004multilabel,
  title={Multilabel SVM active learning for image classification},
  author={Li, Xuchun and Wang, Lei and Sung, Eric},
  booktitle={2004 International Conference on Image Processing, 2004. ICIP'04.},
  volume={4},
  pages={2207--2210},
  year={2004},
  organization={IEEE}
}

@inproceedings{katakis2008multilabel,
  title={Multilabel text classification for automated tag suggestion},
  author={Katakis, Ioannis and Tsoumakas, Grigorios and Vlahavas, Ioannis},
  booktitle={Proceedings of the ECML/PKDD},
  volume={18},
  pages={5},
  year={2008},
  organization={Citeseer}
}

@inproceedings{pang2011multimodal,
  title={Multimodal learning for multi-label image classification},
  author={Pang, Yanwei and Ma, Zhao and Yuan, Yuan and Li, Xuelong and Wang, Kongqiao},
  booktitle={2011 18th IEEE International Conference on Image Processing},
  pages={1797--1800},
  year={2011},
  organization={IEEE}
}

@inproceedings{yang2018complex,
  title={Complex object classification: A multi-modal multi-instance multi-label deep network with optimal transport},
  author={Yang, Yang and Wu, Yi-Feng and Zhan, De-Chuan and Liu, Zhi-Bin and Jiang, Yuan},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2594--2603},
  year={2018}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{huang2020pixel,
  title={Pixel-bert: Aligning image pixels with text by deep multi-modal transformers},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  journal={arXiv preprint arXiv:2004.00849},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}



@inproceedings{alayrac2020self,
  title={{S}elf-{S}upervised {M}ulti{M}odal {V}ersatile {N}etworks},
  author={Alayrac, Jean-Baptiste and Recasens, Adri{\`a} and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  booktitle={NeurIPS},
  year={2020}
}



@article{baltrusaitisMultimodalMachineLearning2019,
  title = {Multimodal {{Machine Learning}}: {{A Survey}} and {{Taxonomy}}},
  shorttitle = {Multimodal {{Machine Learning}}},
  author = {Baltrušaitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  year = {2019},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {41},
  number = {2},
  pages = {423--443},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2018.2798607},
  journal = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Hidden Markov models,introductory,machine learning,Media,Multimedia communication,Multimodal,Speech,Speech recognition,Streaming media,survey,Visualization}
}



@InProceedings{Veit_2018_CVPR,
author = {Veit, Andreas and Nickel, Maximilian and Belongie, Serge and van der Maaten, Laurens},
title = {Separating Self-Expression and Visual Content in Hashtag Supervision},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}




@inproceedings{bagher-zadeh-etal-2018-multimodal,
title = "Multimodal Language Analysis in the Wild: {CMU}-{MOSEI} Dataset and Interpretable Dynamic Fusion Graph",
author = "{Bagher Zadeh}, AmirAli  and Liang, Paul Pu  and Poria, Soujanya  and Cambria, Erik  and Morency, Louis-Philippe",
booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
month = jul,
year = "2018",
address = "Melbourne, Australia",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/P18-1208",
doi = "10.18653/v1/P18-1208",
pages = "2236--2246",
}


@ARTICLE{semihet_three_way_Lei_2020,
  author={Lei, Jianjun and Song, Yuxin and Peng, Bo and Ma, Zhanyu and Shao, Ling and Song, Yi-Zhe},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Semi-Heterogeneous Three-Way Joint Embedding Network for Sketch-Based Image Retrieval}, 
  year={2020},
  volume={30},
  number={9},
  pages={3226-3237},
  doi={10.1109/TCSVT.2019.2936710}}
  
  
  
  

@article{Mittal2020M3ER, 
title={M3ER: Multiplicative Multimodal Emotion Recognition using Facial, Textual, and Speech Cues}, volume={34}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/5492}, 
DOI={10.1609/aaai.v34i02.5492},
number={02}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Mittal, Trisha and Bhattacharya, Uttaran and Chandra, Rohan and Bera, Aniket and Manocha, Dinesh}, 
year={2020}, 
month={Apr.}, 
pages={1359-1367}
}


@ARTICLE{het_data_fusion_liu_IEEE_2017,
  author={Liu, Zuozhu and Zhang, Wenyu and Lin, Shaowei and Quek, Tony Q.S.},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Heterogeneous Sensor Data Fusion By Deep Multimodal Encoding}, 
  year={2017},
  volume={11},
  number={3},
  pages={479-491},
  doi={10.1109/JSTSP.2017.2679538}}
  
  
@inproceedings{Deception_ICMI_2014,
author = {Abouelenien, Mohamed and P\'{e}rez-Rosas, Veronica and Mihalcea, Rada and Burzo, Mihai},
title = {Deception Detection Using a Multimodal Approach},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2663229},
doi = {10.1145/2663204.2663229},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {58–65},
numpages = {8},
keywords = {deception detection, multimodal processing},
location = {Istanbul, Turkey},
series = {ICMI '14}
}



@article{DBLP:journals/corr/abs-1906-03327,
  author    = {Antoine Miech and
               Dimitri Zhukov and
               Jean{-}Baptiste Alayrac and
               Makarand Tapaswi and
               Ivan Laptev and
               Josef Sivic},
  title     = {HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million
               Narrated Video Clips},
  journal   = {CoRR},
  volume    = {abs/1906.03327},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.03327},
  eprinttype = {arXiv},
  eprint    = {1906.03327},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-03327.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{tursun2021efficient,
  title={An efficient framework for zero-shot sketch-based image retrieval},
  author={Tursun, Osman and Denman, Simon and Sridharan, Sridha and Goan, Ethan and Fookes, Clinton},
  journal={arXiv preprint arXiv:2102.04016},
  year={2021}
}


 
 @inproceedings{wav2vec2,
 author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
 booktitle = {Neural Information Processing Systems (NeurIPS)},
 title = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
 year = {2020}
}

@inproceedings{relu2010,
  author={Vinod Nair and Geoffrey E. Hinton},
  title={Rectified Linear Units Improve Restricted Boltzmann Machines},
  year={2010},
  cdate={1262304000000},
  pages={807-814},
  url={https://icml.cc/Conferences/2010/papers/432.pdf},
  booktitle={ICML},
}


@article{ruder2016overviewSGD,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@article{van2008tsne,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@inproceedings{Hoffer2015,
abstract = {Deep learning has proven itself as a successful set of models for learning useful semantic representations of data. These, however, are mostly implicitly learned as part of a classification task. In this paper we propose the triplet network model, which aims to learn useful representations by distance comparisons. A similar model was defined by Wang et al. (2014), tailor made for learning a ranking for image information retrieval. Here we demonstrate using various datasets that our model learns a better representation than that of its immediate competitor, the Siamese network. We also discuss future possible usage as a framework for unsupervised learning.},
address = {Cham},
author = {Hoffer, Elad and Ailon, Nir},
booktitle = {SIMBAD 2015: Similarity-Based Pattern Recognition},
doi = {10.1007/978-3-319-24261-3_7},
editor = {Feragen, Aasa and Pelillo, Marcello and Loog, Marco},
file = {:Users/eman7613/Library/Application Support/Mendeley Desktop/Downloaded/Hoffer, Ailon - 2015 - Deep Metric Learning Using Triplet Network.pdf:pdf},
isbn = {978-3-319-24261-3},
mendeley-groups = {Machine Learning/Metrics/metric learning},
pages = {84--92},
publisher = {Springer International Publishing},
title = {{Deep Metric Learning Using Triplet Network}},
url = {https://doi.org/10.1007/978-3-319-24261-3{\_}7},
year = {2015}
}
@inproceedings{Schroff2015,
author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2015.7298682},
file = {:Users/eman7613/Library/Application Support/Mendeley Desktop/Downloaded/Schroff, Kalenichenko, Philbin - 2015 - FaceNet A unified embedding for face recognition and clustering.pdf:pdf},
isbn = {978-1-4673-6964-0},
keywords = {triplet loss},
mendeley-groups = {Machine Learning/Metrics/metric learning},
mendeley-tags = {triplet loss},
month = {jun},
pages = {815--823},
publisher = {IEEE},
title = {{FaceNet: A unified embedding for face recognition and clustering}},
url = {http://ieeexplore.ieee.org/document/7298682/},
year = {2015}
}
@proceedings{DBLP:conf/eccv/2018-9,
doi = {10.1007/978-3-030-01240-3},
editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
isbn = {978-3-030-01239-7},
mendeley-groups = {Machine Learning/Metrics/metric learning},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Computer Vision - {\{}ECCV{\}} 2018 - 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part {\{}IX{\}}}},
url = {https://doi.org/10.1007/978-3-030-01240-3},
volume = {11213},
year = {2018}
}
@inproceedings{DBLP:conf/eccv/ZhaoJQLH18,
annote = {Use a gan to generate triplets},
author = {Zhao, Yiru and Jin, Zhongming and Qi, Guo-Jun and Lu, Hongtao and Hua, Xian-Sheng},
booktitle = {Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part IX},
doi = {10.1007/978-3-030-01240-3_31},
editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
file = {:Users/eman7613/Downloads/Yiru{\_}Zhao{\_}A{\_}Principled{\_}Approach{\_}ECCV{\_}2018{\_}paper.pdf:pdf},
isbn = {978-3-030-01239-7},
mendeley-groups = {Machine Learning/Metrics/metric learning},
pages = {508--524},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{An Adversarial Approach to Hard Triplet Generation}},
url = {https://doi.org/10.1007/978-3-030-01240-3{\_}31},
volume = {11213},
year = {2018}
}
@article{Zhai2018,
abstract = {The recent research for person re-identification has been focused on two trends. One is learning the part-based local features to form more informative feature descriptors. The other is designing effective metric learning loss functions such as the triplet loss family. We argue that learning global features with classification loss could achieve the same goal, even with some simple and cost-effective architecture design. In this paper, we first explain why the person re-id framework with standard classification loss usually has inferior performance compared to metric learning. Based on that, we further propose a person re-id framework featured by channel grouping and multi-branch strategy, which divides global features into multiple channel groups and learns the discriminative channel group features by multi-branch classification layers. The extensive experiments show that our framework outperforms prior state-of-the-arts in terms of both accuracy and inference speed.},
archivePrefix = {arXiv},
arxivId = {1809.05864},
author = {Zhai, Yao and Guo, Xun and Lu, Yan and Li, Houqiang},
eprint = {1809.05864},
file = {:Users/eman7613/Downloads/1703.07737.pdf:pdf},
journal = {ArXiv e-prints},
mendeley-groups = {Biometrics/Finger Prints/Computer Vision/re-identification/perspn,Machine Learning/Metrics/metric learning},
title = {{In Defense of the Triplet Loss for Person Re-Identification}},
url = {http://arxiv.org/abs/1809.05864},
year = {2018}
}
@article{Chechik:2010:LSO:1756006.1756042,
abstract = {Learning a measure of similarity between pairs of objects is an important generic problem in machine learning. It is particularly useful in large scale applications like searching for an image that is similar to a given image or finding videos that are relevant to a given video. In these tasks, users look for objects that are not only visually similar but also semantically related to a given object. Unfortunately, the approaches that exist today for learning such semantic similarity do not scale to large data sets. This is both because typically their CPU and storage requirements grow quadratically with the sample size, and because many methods impose complex positivity constraints on the space of learned similarity functions. The current paper presents OASIS, an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations. OASIS is an online dual approach using the passive-aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost. Our experiments show that OASIS is both fast and accurate at a wide range of scales: for a data set with thousands of images, it achieves better results than existing state-of-the-art methods, while being an order of magnitude faster. For large, web scale, data sets, OASIS can be trained on more than two million images from 150K text queries within 3 days on a single CPU. On this large scale data set, human evaluations showed that 35{\%} of the ten nearest neighbors of a given test image, as found by OASIS, were semantically relevant to that image. This suggests that query independent similarity could be accurately learned even for large scale data sets that could not be handled before.},
author = {Chechik, Gal and Sharma, Varun and Shalit, Uri and Bengio, Samy},
file = {:Users/eman7613/Downloads/chechik10a.pdf:pdf},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
mendeley-groups = {Machine Learning/Metrics/metric learning},
month = {mar},
pages = {1109--1135},
publisher = {JMLR.org},
title = {{Large Scale Online Learning of Image Similarity Through Ranking}},
url = {http://dl.acm.org/citation.cfm?id=1756006.1756042},
volume = {11},
year = {2010}
}
@inproceedings{Musgrave2020,
abstract = {Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental setup of these papers, and propose a new way to evaluate metric learning algorithms. Finally, we present experimental results that show that the improvements over time have been marginal at best.},
archivePrefix = {arXiv},
arxivId = {2003.08505},
author = {Musgrave, Kevin and Belongie, Serge and Lim, Ser-Nam},
booktitle = {ECCV},
eprint = {2003.08505},
file = {:Users/eman7613/Downloads/2003.08505.pdf:pdf},
keywords = {deep metric learning},
mendeley-groups = {Machine Learning/Metrics/metric learning,Machine Learning/reproducability/attempts},
title = {{A Metric Learning Reality Check}},
url = {http://arxiv.org/abs/2003.08505},
year = {2020}
}
@inproceedings{Raff2020c,
abstract = {There has been increasing concern within the machine learning community that we are in a reproducibility crisis. As many have begun to work on this problem, all work we are aware of treat the issue of reproducibility as an intrinsic binary property: a paper is or is not reproducible. Instead, we consider modeling the reproducibility of a paper as a survival analysis problem. We argue that this perspective represents a more accurate model of the underlying meta-science question of reproducible research, and we show how a survival analysis allows us to draw new insights that better explain prior longitudinal data. The data and code can be found at https://github.com/EdwardRaff/Research-Reproducibility-Survival-Analysis},
archivePrefix = {arXiv},
arxivId = {2012.09932},
author = {Raff, Edward},
booktitle = {The Thirty-Fifth AAAI Conference on Artificial Intelligence},
eprint = {2012.09932},
file = {:Users/eman7613/Downloads/2012.09932.pdf:pdf},
title = {{Research Reproducibility as a Survival Analysis}},
url = {http://arxiv.org/abs/2012.09932},
year = {2021}
}
@inproceedings{Raff2019_quantify_repro,
abstract = {What makes a paper independently reproducible? Debates on reproducibility center around intuition or assumptions but lack empirical results. Our field focuses on releasing code, which is important, but is not sufficient for determining reproducibility. We take the first step toward a quantifiable answer by manually attempting to implement 255 papers published from 1984 until 2017, recording features of each paper, and performing statistical analysis of the results. For each paper, we did not look at the authors code, if released, in order to prevent bias toward discrepancies between code and paper.},
archivePrefix = {arXiv},
arxivId = {1909.06674},
author = {Raff, Edward},
booktitle = {NeurIPS},
eprint = {1909.06674},
file = {:Users/eman7613/Downloads/1909.06674.pdf:pdf},
mendeley-groups = {Machine Learning/reproducability/attempts},
title = {{A Step Toward Quantifying Independently Reproducible Machine Learning Research}},
url = {http://arxiv.org/abs/1909.06674},
year = {2019}
}
@inproceedings{10.1145/3357384.3357889,
author = {Zheng, Wen and Zhou, Ke},
title = {Enhancing Conversational Dialogue Models with Grounded Knowledge},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357889},
doi = {10.1145/3357384.3357889},
abstract = {Leveraging external knowledge to enhance conversational models has become a popular research area in recent years. Compared to vanilla generative models, the knowledge-grounded models may produce more informative and engaging responses. Although various approaches have been proposed in the past, how to effectively incorporate knowledge remains an open research question. It is unclear how much external knowledge should be retrieved and what is the optimal way to enhance the conversational model, trading off between relevant information and noise. Therefore, in this paper, we aim to bridge the gap by first extensively evaluating various types of state-of-the-art knowledge-grounded conversational models, including recurrent neural network based, memory networks based, and Transformer based models. We demonstrate empirically that those conversational models can only be enhanced with the right amount of external knowledge. To effectively leverage information originated from external knowledge, we propose a novel Transformer with Expanded Decoder (Transformer-ED or TED for short), which can automatically tune the weights for different sources of evidence when generating responses. Our experiments show that our proposed model outperforms state-of-the-art models in terms of both quality and diversity.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {709–718},
numpages = {10},
keywords = {transformer-ed, multi-task learning, knowledge-grounded, generative model, ted, sequence-to-sequence, transformer, memory network, copy-mechanism},
location = {Beijing, China},
series = {CIKM '19}
}
@inbook{10.1145/3397271.3401097,
author = {Meng, Chuan and Ren, Pengjie and Chen, Zhumin and Sun, Weiwei and Ren, Zhaochun and Tu, Zhaopeng and Rijke, Maarten de},
title = {DukeNet: A Dual Knowledge Interaction Network for Knowledge-Grounded Conversation},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401097},
abstract = {Today's conversational agents often generate responses that not sufficiently informative. One way of making them more informative is through the use of of external knowledge sources with so-called Knowledge-Grounded Conversations (KGCs). In this paper, we target the Knowledge Selection (KS) task, a key ingredient in KGC, that is aimed at selecting the appropriate knowledge to be used in the next response. Existing approaches to Knowledge Selection (KS) based on learned representations of the conversation context, that is previous conversation turns, and use Maximum Likelihood Estimation (MLE) to optimize KS. Such approaches have two main limitations. First, they do not explicitly track what knowledge has been used in the conversation nor how topics have shifted during the conversation. Second, MLE often relies on a limited set of example conversations for training, from which it is hard to infer that facts retrieved from the knowledge source can be re-used in multiple conversation contexts, and vice versa.We propose Dual Knowledge Interaction Network (DukeNet), a framework to address these challenges. DukeNet explicitly models knowledge tracking and knowledge shifting as dual tasks. We also design Dual Knowledge Interaction Learning (DukeL), an unsupervised learning scheme to train DukeNet by facilitating interactions between knowledge tracking and knowledge shifting, which, in turn, enables DukeNet to explore extra knowledge besides the knowledge encountered in the training set. This dual process also allows us to define rewards that help us to optimize both knowledge tracking and knowledge shifting. Experimental results on two public KGC benchmarks show that DukeNet significantly outperforms state-of-the-art methods in terms of both automatic and human evaluations, indicating that DukeNet enhanced by DukeL can select more appropriate knowledge and hence generate more informative and engaging responses.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1151–1160},
numpages = {10}
}
@inbook{10.1145/3397271.3401232,
author = {Jangra, Anubhav and Saha, Sriparna and Jatowt, Adam and Hasanuzzaman, Mohammad},
title = {Multi-Modal Summary Generation Using Multi-Objective Optimization},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401232},
abstract = {Significant development of communication technology over the past few years has motivated research in multi-modal summarization techniques. A majority of the previous works on multi-modal summarization focus on text and images. In this paper, we propose a novel extractive multi-objective optimization based model to produce a multi-modal summary containing text, images, and videos. Important objectives such as intra-modality salience, cross-modal redundancy and cross-modal similarity are optimized simultaneously in a multi-objective optimization framework to produce effective multi-modal output. The proposed model has been evaluated separately for different modalities, and has been found to perform better than state-of-the-art approaches.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1745–1748},
numpages = {4}
}
@inproceedings{10.1145/3331184.3331213,
author = {Hu, Peng and Zhen, Liangli and Peng, Dezhong and Liu, Pei},
title = {Scalable Deep Multimodal Learning for Cross-Modal Retrieval},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331213},
doi = {10.1145/3331184.3331213},
abstract = {Cross-modal retrieval takes one type of data as the query to retrieve relevant data of another type. Most of existing cross-modal retrieval approaches were proposed to learn a common subspace in a joint manner, where the data from all modalities have to be involved during the whole training process. For these approaches, the optimal parameters of different modality-specific transformations are dependent on each other and the whole model has to be retrained when handling samples from new modalities. In this paper, we present a novel cross-modal retrieval method, called Scalable Deep Multimodal Learning (SDML). It proposes to predefine a common subspace, in which the between-class variation is maximized while the within-class variation is minimized. Then, it trains m modality-specific networks for m modalities (one network for each modality) to transform the multimodal data into the predefined common subspace to achieve multimodal learning. Unlike many of the existing methods, our method can train different modality-specific networks independently and thus be scalable to the number of modalities. To the best of our knowledge, the proposed SDML could be one of the first works to independently project data of an unfixed number of modalities into a predefined common subspace. Comprehensive experimental results on four widely-used benchmark datasets demonstrate that the proposed method is effective and efficient in multimodal learning and outperforms the state-of-the-art methods in cross-modal retrieval.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {635–644},
numpages = {10},
keywords = {multimodal learning, representation learning, cross-modal retrieval},
location = {Paris, France},
series = {SIGIR'19}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@InProceedings{Zhuge_2021_CVPR_VLP,
    author    = {Zhuge, Mingchen and Gao, Dehong and Fan, Deng-Ping and Jin, Linbo and Chen, Ben and Zhou, Haoming and Qiu, Minghui and Shao, Ling},
    title     = {Kaleido-BERT: Vision-Language Pre-Training on Fashion Domain},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {12647-12657}
}


@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}